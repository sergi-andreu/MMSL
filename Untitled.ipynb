{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87aea4bc-c577-499e-af17-a155f66a5e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllMethods.txt\n",
      "\\begin{tabular}{llllll}\n",
      "{} & {} & {Accuracy} & {Recall} & {Precision} & {F1 Score} \\\\\n",
      "LDA & lsqr Solver & $77.5±5.2\\%$ & $\\mathbf{84.1±4.8\\%$ & $74.9±6.4\\%$ & $79.0±4.3\\%$ \\\\\n",
      "QDA & lsqr Solver & $71.3±1.5\\%$ & $\\mathbf{72.2±5.3\\%$ & $70.8±3.7\\%$ & $71.3±3.2\\%$ \\\\\n",
      "Logistic Regression & l1 Penalty & $76.7±5.7\\%$ & $\\mathbf{82.3±6.0\\%$ & $74.7±6.3\\%$ & $78.1±4.6\\%$ \\\\\n",
      "\\multirow[c]{2}{*}{SVM} & linear Kernel & $75.6±5.0\\%$ & $\\mathbf{80.2±4.6\\%$ & $73.5±6.2\\%$ & $76.6±4.9\\%$ \\\\\n",
      " & rbf Kernel & $80.2±5.3\\%$ & $\\mathbf{86.6±5.5\\%$ & $77.5±5.2\\%$ & $81.6±3.5\\%$ \\\\\n",
      "\\multirow[c]{2}{*}{K Nearest Neighbors} & 5 Number of neighbors & $75.7±4.8\\%$ & $\\mathbf{83.4±3.6\\%$ & $72.5±5.6\\%$ & $77.4±4.4\\%$ \\\\\n",
      " & 50 Number of neighbors & $73.9±4.5\\%$ & $\\mathbf{86.3±8.9\\%$ & 69.8±4.0\\%$ & $76.7±3.2\\%$ \\\\\n",
      "\\multirow[c]{2}{*}{Decision Trees} & gini Criterion & $75.9±4.5\\%$ & $\\mathbf{77.6±5.0\\%$ & $75.3±6.4\\%$ & $76.3±4.5\\%$ \\\\\n",
      " & entropy Criterion & $74.7±4.7\\%$ & $\\mathbf{75.0±6.0\\%$ & $75.0±3.5\\%$ & $74.8±3.5\\%$ \\\\\n",
      "\\multirow[c]{2}{*}{Random Forest} & 50 Number of estimators & $83.2±4.6\\%$ & $\\mathbf{87.3±4.2\\%$ & $81.3±7.8\\%$ & $83.9±4.3\\%$ \\\\\n",
      " & 150 Number of estimators & $83.8±4.3\\%$ & $\\mathbf{86.5±5.0\\%$ & $82.5±5.5\\%$ & $84.3±3.7\\%$ \\\\\n",
      "\\multirow[c]{2}{*}{Bagging} & 50 Number of estimators & $82.6±4.8\\%$ & $\\mathbf{84.3±6.1\\%$ & $82.4±7.1\\%$ & $83.0±4.1\\%$ \\\\\n",
      " & 150 Number of estimators & $82.6±3.4\\%$ & $\\mathbf{84.7±6.1\\%$ & $82.1±6.3\\%$ & $83.0±2.5\\%$ \\\\\n",
      "\\multirow[c]{2}{*}{NN} & (20, 10, 5) Hidden layers & $76.3±4.1\\%$ & $76.6±3.0\\%$ & $\\mathbf{76.7±5.8\\%$ & $76.5±3.1\\%$ \\\\\n",
      " & (5, 5) Hidden layers & $77.5±4.0\\%$ & $\\mathbf{80.7±4.5\\%$ & $76.3±5.4\\%$ & $78.3±3.2\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "bagging.txt\n",
      "\\begin{tabular}{lllllllll}\n",
      "{} & {10 Number of estimators} & {20 Number of estimators} & {50 Number of estimators} & {100 Number of estimators} & {150 Number of estimators} & {200 Number of estimators} & {250 Number of estimators} & {300 Number of estimators} \\\\\n",
      "Accuracy & $78.0±3.5\\%$ & $82.0±3.0\\%$ & $\\mathbf{82.6±4.8\\%$ & $82.4±4.4\\%$ & $82.6±3.4\\%$ & $81.0±5.3\\%$ & $82.2±3.9\\%$ & $81.8±3.8\\%$ \\\\\n",
      "Recall & $83.4±6.1\\%$ & $\\mathbf{84.9±4.5\\%$ & $84.3±6.1\\%$ & $84.3±6.1\\%$ & $84.7±6.1\\%$ & $82.0±7.0\\%$ & $83.0±5.3\\%$ & $83.1±6.2\\%$ \\\\\n",
      "Precision & $75.5±3.2\\%$ & $80.5±3.4\\%$ & $\\mathbf{82.4±7.1\\%$ & $82.2±7.8\\%$ & $82.1±6.3\\%$ & $81.2±6.6\\%$ & $82.4±6.7\\%$ & $81.7±5.7\\%$ \\\\\n",
      "F1 Score & $79.1±2.5\\%$ & $82.5±2.0\\%$ & $\\mathbf{83.0±4.1\\%$ & $82.8±3.7\\%$ & $83.0±2.5\\%$ & $81.3±4.5\\%$ & $82.4±3.3\\%$ & $82.1±3.0\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "decisiontree.txt\n",
      "\\begin{tabular}{lll}\n",
      "{} & {gini Criterion} & {entropy Criterion} \\\\\n",
      "Accuracy & $\\mathbf{75.9±4.5\\%$ & $74.7±4.7\\%$ \\\\\n",
      "Recall & $\\mathbf{77.6±5.0\\%$ & $75.0±6.0\\%$ \\\\\n",
      "Precision & $\\mathbf{75.3±6.4\\%$ & $75.0±3.5\\%$ \\\\\n",
      "F1 Score & $\\mathbf{76.3±4.5\\%$ & $74.8±3.5\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "knearest.txt\n",
      "\\begin{tabular}{llllllll}\n",
      "{} & {1 Number of neighbors} & {5 Number of neighbors} & {10 Number of neighbors} & {15 Number of neighbors} & {20 Number of neighbors} & {50 Number of neighbors} & {100 Number of neighbors} \\\\\n",
      "Accuracy & $74.3±3.9\\%$ & $\\mathbf{75.7±4.8\\%$ & $75.1±2.7\\%$ & $73.1±4.7\\%$ & $71.7±3.1\\%$ & $73.9±4.5\\%$ & $73.4±3.2\\%$ \\\\\n",
      "Recall & $77.4±4.5\\%$ & $83.4±3.6\\%$ & $\\mathbf{91.0±3.2\\%$ & $83.3±5.9\\%$ & $87.4±6.2\\%$ & $86.3±8.9\\%$ & 90.2±8.4\\%$ \\\\\n",
      "Precision & $\\mathbf{73.3±4.1\\%$ & $72.5±5.6\\%$ & 69.2±4.3\\%$ & 69.4±2.7\\%$ & 66.7±2.5\\%$ & 69.8±4.0\\%$ & 67.9±4.1\\%$ \\\\\n",
      "F1 Score & $75.1±2.6\\%$ & $77.4±4.4\\%$ & $\\mathbf{78.5±2.4\\%$ & $75.6±3.2\\%$ & $75.5±1.9\\%$ & $76.7±3.2\\%$ & $77.1±2.4\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "lda.txt\n",
      "\\begin{tabular}{lll}\n",
      "{} & {svd Solver} & {lsqr Solver} \\\\\n",
      "Accuracy & $\\mathbf{77.5±5.2\\%$ & $\\mathbf{77.5±5.2\\%$ \\\\\n",
      "Recall & $\\mathbf{84.1±4.8\\%$ & $\\mathbf{84.1±4.8\\%$ \\\\\n",
      "Precision & $\\mathbf{74.9±6.4\\%$ & $\\mathbf{74.9±6.4\\%$ \\\\\n",
      "F1 Score & $\\mathbf{79.0±4.3\\%$ & $\\mathbf{79.0±4.3\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "LeaderBoard.txt\n",
      "\\begin{tabular}{llllll}\n",
      "{} & {} & {Accuracy} & {Recall} & {Precision} & {F1 Score} \\\\\n",
      "SVM & rbf Kernel & $80.2±5.3\\%$ & $\\mathbf{86.6±5.5\\%$ & $77.5±5.2\\%$ & $81.6±3.5\\%$ \\\\\n",
      "\\multirow[c]{8}{*}{Random Forest} & 10 Number of estimators & $79.5±4.6\\%$ & $\\mathbf{86.7±3.4\\%$ & $76.3±6.1\\%$ & $81.0±3.5\\%$ \\\\\n",
      " & 20 Number of estimators & $81.4±4.4\\%$ & $\\mathbf{84.6±5.8\\%$ & $80.1±7.1\\%$ & $82.0±4.0\\%$ \\\\\n",
      " & 50 Number of estimators & $83.2±4.6\\%$ & $\\mathbf{87.3±4.2\\%$ & $81.3±7.8\\%$ & $83.9±4.3\\%$ \\\\\n",
      " & 100 Number of estimators & $83.4±3.6\\%$ & $\\mathbf{86.1±5.1\\%$ & $82.2±7.0\\%$ & $83.8±3.4\\%$ \\\\\n",
      " & 150 Number of estimators & $83.8±4.3\\%$ & $\\mathbf{86.5±5.0\\%$ & $82.5±5.5\\%$ & $84.3±3.7\\%$ \\\\\n",
      " & 200 Number of estimators & $83.8±4.9\\%$ & $\\mathbf{86.0±7.0\\%$ & $83.1±6.3\\%$ & $84.2±4.2\\%$ \\\\\n",
      " & 250 Number of estimators & $82.6±4.9\\%$ & $\\mathbf{85.5±6.4\\%$ & $81.6±6.5\\%$ & $83.2±4.1\\%$ \\\\\n",
      " & 300 Number of estimators & $83.0±5.2\\%$ & $\\mathbf{86.0±7.4\\%$ & $82.0±6.6\\%$ & $83.6±4.5\\%$ \\\\\n",
      "\\multirow[c]{7}{*}{Bagging} & 20 Number of estimators & $82.0±3.0\\%$ & $\\mathbf{84.9±4.5\\%$ & $80.5±3.4\\%$ & $82.5±2.0\\%$ \\\\\n",
      " & 50 Number of estimators & $82.6±4.8\\%$ & $\\mathbf{84.3±6.1\\%$ & $82.4±7.1\\%$ & $83.0±4.1\\%$ \\\\\n",
      " & 100 Number of estimators & $82.4±4.4\\%$ & $\\mathbf{84.3±6.1\\%$ & $82.2±7.8\\%$ & $82.8±3.7\\%$ \\\\\n",
      " & 150 Number of estimators & $82.6±3.4\\%$ & $\\mathbf{84.7±6.1\\%$ & $82.1±6.3\\%$ & $83.0±2.5\\%$ \\\\\n",
      " & 200 Number of estimators & $81.0±5.3\\%$ & $\\mathbf{82.0±7.0\\%$ & $81.2±6.6\\%$ & $81.3±4.5\\%$ \\\\\n",
      " & 250 Number of estimators & $82.2±3.9\\%$ & $\\mathbf{83.0±5.3\\%$ & $82.4±6.7\\%$ & $82.4±3.3\\%$ \\\\\n",
      " & 300 Number of estimators & $81.8±3.8\\%$ & $\\mathbf{83.1±6.2\\%$ & $81.7±5.7\\%$ & $82.1±3.0\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "logistic.txt\n",
      "\\begin{tabular}{lllll}\n",
      "{} & {l1 Penalty} & {l2 Penalty} & {elasticnet Penalty} & {none Penalty} \\\\\n",
      "Accuracy & $\\mathbf{76.7±5.7\\%$ & $76.3±5.9\\%$ & $76.3±5.9\\%$ & $76.5±5.8\\%$ \\\\\n",
      "Recall & $\\mathbf{82.3±6.0\\%$ & $81.1±6.0\\%$ & $81.1±6.0\\%$ & $81.1±6.0\\%$ \\\\\n",
      "Precision & $74.7±6.3\\%$ & $74.8±6.7\\%$ & $74.8±6.7\\%$ & $\\mathbf{75.1±6.6\\%$ \\\\\n",
      "F1 Score & $\\mathbf{78.1±4.6\\%$ & $77.6±4.7\\%$ & $77.6±4.7\\%$ & $77.7±4.6\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "nn.txt\n",
      "\\begin{tabular}{lll}\n",
      "{} & {(20, 10, 5) Hidden layers} & {(5, 5) Hidden layers} \\\\\n",
      "Accuracy & $76.3±4.1\\%$ & $\\mathbf{77.5±4.0\\%$ \\\\\n",
      "Recall & $76.6±3.0\\%$ & $\\mathbf{80.7±4.5\\%$ \\\\\n",
      "Precision & $\\mathbf{76.7±5.8\\%$ & $76.3±5.4\\%$ \\\\\n",
      "F1 Score & $76.5±3.1\\%$ & $\\mathbf{78.3±3.2\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "qda.txt\n",
      "\\begin{tabular}{lll}\n",
      "{} & {svd Solver} & {lsqr Solver} \\\\\n",
      "Accuracy & $\\mathbf{71.3±1.5\\%$ & $\\mathbf{71.3±1.5\\%$ \\\\\n",
      "Recall & $\\mathbf{72.2±5.3\\%$ & $\\mathbf{72.2±5.3\\%$ \\\\\n",
      "Precision & $\\mathbf{70.8±3.7\\%$ & $\\mathbf{70.8±3.7\\%$ \\\\\n",
      "F1 Score & $\\mathbf{71.3±3.2\\%$ & $\\mathbf{71.3±3.2\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "randomforest.txt\n",
      "\\begin{tabular}{lllllllll}\n",
      "{} & {10 Number of estimators} & {20 Number of estimators} & {50 Number of estimators} & {100 Number of estimators} & {150 Number of estimators} & {200 Number of estimators} & {250 Number of estimators} & {300 Number of estimators} \\\\\n",
      "Accuracy & $79.5±4.6\\%$ & $81.4±4.4\\%$ & $83.2±4.6\\%$ & $83.4±3.6\\%$ & $83.8±4.3\\%$ & $\\mathbf{83.8±4.9\\%$ & $82.6±4.9\\%$ & $83.0±5.2\\%$ \\\\\n",
      "Recall & $86.7±3.4\\%$ & $84.6±5.8\\%$ & $\\mathbf{87.3±4.2\\%$ & $86.1±5.1\\%$ & $86.5±5.0\\%$ & $86.0±7.0\\%$ & $85.5±6.4\\%$ & $86.0±7.4\\%$ \\\\\n",
      "Precision & $76.3±6.1\\%$ & $80.1±7.1\\%$ & $81.3±7.8\\%$ & $82.2±7.0\\%$ & $82.5±5.5\\%$ & $\\mathbf{83.1±6.3\\%$ & $81.6±6.5\\%$ & $82.0±6.6\\%$ \\\\\n",
      "F1 Score & $81.0±3.5\\%$ & $82.0±4.0\\%$ & $83.9±4.3\\%$ & $83.8±3.4\\%$ & $\\mathbf{84.3±3.7\\%$ & $84.2±4.2\\%$ & $83.2±4.1\\%$ & $83.6±4.5\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "svm.txt\n",
      "\\begin{tabular}{lllll}\n",
      "{} & {linear Kernel} & {poly Kernel} & {rbf Kernel} & {sigmoid Kernel} \\\\\n",
      "Accuracy & $75.6±5.0\\%$ & $75.1±5.6\\%$ & $\\mathbf{80.2±5.3\\%$ & $73.3±3.8\\%$ \\\\\n",
      "Recall & $80.2±4.6\\%$ & $\\mathbf{87.4±7.5\\%$ & $86.6±5.5\\%$ & $78.4±6.4\\%$ \\\\\n",
      "Precision & $73.5±6.2\\%$ & $70.4±3.9\\%$ & $\\mathbf{77.5±5.2\\%$ & $71.3±4.8\\%$ \\\\\n",
      "F1 Score & $76.6±4.9\\%$ & $77.9±4.5\\%$ & $\\mathbf{81.6±3.5\\%$ & $74.5±3.9\\%$ \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for filename in os.listdir(\"Tables\"):\n",
    "    with open(\"Tables/\" + filename, 'r') as f:\n",
    "        filedata = f.read()\n",
    "        filedata = filedata.replace('%', '\\%$')\n",
    "        filedata = filedata.replace('\\\\font-weightbold ', '$\\mathbf{')\n",
    "        filedata = filedata.replace('& 7', '& $7')\n",
    "        filedata = filedata.replace('& 8', '& $8')\n",
    "        print(filename)\n",
    "        print(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e43328-b5ae-496a-8c95-9e5495ad44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Tables/AllMethods.txt', 'w') as f:\n",
    "    f.write(results_df.style.highlight_max(props='font-weight:bold;', axis = 1).to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
